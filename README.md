# RAG Chatbot with Azure AI Foundry + Semantic Kernel

This repository implements an **end-to-end Retrieval-Augmented Generation (RAG) chatbot** using:

- **Azure AI Foundry (Copilot SDK)** â€“ resource orchestration, evaluation  
- **Azure AI Agent Services** â€“ agent lifecycle and orchestration  
- **Azure AI Search** â€“ vector search + hybrid retrieval  
- **Semantic Kernel (SK)** â€“ agent and skill orchestration  
- **Streamlit** â€“ user-friendly chatbot interface  
- **GenAIOps practices** â€“ reproducibility, observability, evaluation  

References:  
- [Part 1 â€“ Create resources](https://learn.microsoft.com/en-us/azure/ai-foundry/tutorials/copilot-sdk-create-resources?tabs=windows)  
- [Part 2 â€“ Build RAG](https://learn.microsoft.com/en-us/azure/ai-foundry/tutorials/copilot-sdk-build-rag)  
- [Part 3 â€“ Evaluate](https://learn.microsoft.com/en-us/azure/ai-foundry/tutorials/copilot-sdk-evaluate)  
- [Semantic Kernel integration](https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/develop/semantic-kernel)  

---

## ğŸ“‚ Repository Structure

```
ğŸ“¦ rag-chatbot-foundry-sk/
â”œâ”€ README.md
â”œâ”€ pyproject.toml        # managed by uv
â”œâ”€ .env.example
â”œâ”€ data/                 # PDFs to ingest
â”œâ”€ tests/                # evaluation datasets & scripts
â”œâ”€ src/
â”‚  â”œâ”€ config.py
â”‚  â”œâ”€ create_index.py
â”‚  â”œâ”€ ingest_pdfs.py
â”‚  â”œâ”€ chat_backend.py
â”‚  â”œâ”€ sk_orchestrator.py
â”‚  â”œâ”€ agent_services.py
â”‚  â””â”€ ui_streamlit.py
â””â”€ assets/
   â”œâ”€ prompts/
   â””â”€ samples/
```

---

## âš™ï¸ Prerequisites

- Azure subscription with:
  - **Azure AI Foundry hub-based project**
  - **Azure OpenAI models** (chat + embeddings)
  - **Azure AI Search** (Basic tier or higher)
- Python **3.10+**
- **Azure CLI** (`az login`)
- [uv](https://docs.astral.sh/uv/) for environment + dependency management
- Streamlit for UI

---

## ğŸš€ Setup with uv

```bash
# Create and activate environment
uv venv
source .venv/Scripts/activate   # or .venv\Scripts\Activate.ps1 on Windows

# Install dependencies from pyproject.toml
uv pip install -e .
```

> Add new dependencies with:
> ```bash
> uv add streamlit semantic-kernel azure-ai-projects azure-search-documents azure-identity python-dotenv
> ```

---

## ğŸ› ï¸ Workflow

### 1. Configure environment
Copy `.env.example` â†’ `.env` and fill:
```
AIPROJECT_CONNECTION_STRING=<from AI Foundry>
AISEARCH_INDEX_NAME=pdf-qa-index
CHAT_MODEL=gpt-4o-mini
EMBEDDINGS_MODEL=text-embedding-ada-002
```

### 2. Create index
```bash
uv run python -m src.create_index
```

### 3. Ingest PDFs
```bash
uv run python -m src.ingest_pdfs --pdf-dir data
```

### 4. Run chatbot UI
```bash
uv run streamlit run src/ui_streamlit.py
```

Access at `http://localhost:8501`.

---

## ğŸ” Evaluation (GenAIOps)

- Place Q&A test sets under `tests/`
- Run evaluation pipeline:
```bash
uv run pytest tests/
```

---

## ğŸ“ˆ GenAIOps Best Practices

- **Reproducibility** â†’ `uv` + `pyproject.toml` pin dependencies  
- **Observability** â†’ integrate with Application Insights / OpenTelemetry  
- **Evaluation** â†’ Azure AI Foundry eval + local `tests/`  
- **MLOps alignment** â†’ CI/CD for ingestion, SK orchestration, and UI deployment  
- **Governance** â†’ secure connection strings, apply Responsible AI guardrails  

---

## ğŸ”® Next Steps

- Add SK planner for multi-turn memory  
- Containerize with Docker + `uv`  
- Deploy Streamlit app to Azure App Service / Container Apps  
- Publish agent to Copilot Studio  

---

## ğŸ“œ License

MIT (or your organizationâ€™s license).

